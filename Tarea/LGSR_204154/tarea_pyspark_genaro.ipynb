{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea Apache Spark\n",
    ">Importa las librerías necesarias dónde sea necesario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SparkSession\n",
    ">Crea un SparkSession para comenzar la tarea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/12/07 00:13:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"MiAplicacion\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear un DataFrame\n",
    ">Lee el csv datosTarea.csv, mételo a un DF y muéstralo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+--------------------+--------------------+--------------------+--------------------+-------+--------------------+-------------------+--------+-----------+------+\n",
      "|Index|Organization Id|                Name|             Website|             Country|         Description|Founded|            Industry|Number of employees|Networth|stock_price|profit|\n",
      "+-----+---------------+--------------------+--------------------+--------------------+--------------------+-------+--------------------+-------------------+--------+-----------+------+\n",
      "|    1|FAB0d41d5b5d22c|         Ferrell LLC|  https://price.net/|    Papua New Guinea|Horizontal empowe...|   1990|            Plastics|               3498|  402269|         33| 12125|\n",
      "|    2|6A7EdDEA9FaDC52|Mckinney, Riley a...|http://www.hall-b...|             Finland|User-centric syst...|   2015|Glass / Ceramics ...|               4952|  569480|         49| 12001|\n",
      "|    3|0bFED1ADAE4bcC1|          Hester Ltd|http://sullivan-r...|               China|Switchable scalab...|   1971|       Public Safety|               5287|  608005|         26| 17121|\n",
      "|    4|2bFC1Be8a4ce42f|      Holder-Sellers| https://becker.com/|        Turkmenistan|De-engineered sys...|   2004|          Automotive|                921|  105914|         23|  8200|\n",
      "|    5|9eE8A6a4Eb96C24|         Mayer Group|http://www.brewer...|           Mauritius|Synchronized need...|   1991|      Transportation|               7870|  905049|         31|  8599|\n",
      "|    6|cC757116fe1C085|      Henry-Thompson|   http://morse.net/|             Bahamas|Face-to-face well...|   1992|Primary / Seconda...|               4914|  565110|         49|  5389|\n",
      "|    7|219233e8aFF1BC3|      Hansen-Everett|https://www.kidd....|            Pakistan|Seamless disinter...|   2018| Publishing Industry|               7832|  900679|         13|  5700|\n",
      "|    8|ccc93DCF81a31CD|       Mcintosh-Mora|https://www.brook...|Heard Island and ...|Centralized attit...|   1970|     Import / Export|               4389|  504734|         19|  5830|\n",
      "|    9|0B4F93aA06ED03e|            Carr Inc|    http://ross.com/|              Kuwait|Distributed impac...|   1996|            Plastics|               8167|  939204|         16| 15786|\n",
      "|   10|738b5aDe6B1C6A5|          Gaines Inc|http://sandoval-h...|          Uzbekistan|Multi-lateral sca...|   1997|Outsourcing / Off...|               9698| 1115270|         16| 14835|\n",
      "|   11|AE61b8Ffebbc476|          Kidd Group|http://www.lyons....|Bouvet Island (Bo...|Proactive foregro...|   2001|Primary / Seconda...|               7473|  859394|         45| 15424|\n",
      "|   12|eb3B7D06cCdD609|        Crane-Clarke|https://www.sando...|             Denmark|Front-line clear-...|   2014|    Food / Beverages|               9011| 1036264|         26|  8297|\n",
      "|   13|8D0c29189C9798B|Keller, Campos an...|https://www.garne...|             Liberia|Ameliorated direc...|   2020|Museums / Institu...|               2862|  329130|         28| 17043|\n",
      "|   14|D2c91cc03CA394c|         Glover-Pope|http://www.silva....|United Arab Emirates|Persevering conte...|   2013|    Medical Practice|               9079| 1044084|         28| 17809|\n",
      "|   15|C8AC1eaf9C036F4|      Pacheco-Spears|https://aguilar.com/|              Sweden|Secured logistica...|   1984|            Maritime|                769|   88435|         34| 12677|\n",
      "|   16|b5D10A14f7a8AfE|         Hodge-Ayers|http://www.archer...|            Honduras|Future-proofed ra...|   1990| Facilities Services|               8508|  978419|         13| 15797|\n",
      "|   17|68139b5C4De03B4|Bowers, Guerra an...|http://www.carril...|              Uganda|De-engineered tra...|   1972|Primary / Seconda...|               6986|  803389|         34| 12530|\n",
      "|   18|5c2EffEfdba2BdF|     Mckenzie-Melton|http://montoya-th...|           Hong Kong|Reverse-engineere...|   1998|Investment Manage...|               4589|  527735|         11| 16958|\n",
      "|   19|ba179F19F7925f5|         Branch-Mann|http://www.lozano...|            Botswana|Adaptive intangib...|   1999|Architecture / Pl...|               7961|  915514|         47|  8745|\n",
      "|   20|c1Ce9B350BAc66b|      Weiss and Sons|https://barrett.com/|               Korea|Sharable optimal ...|   2011|            Plastics|               5984|  688160|         46| 18079|\n",
      "+-----+---------------+--------------------+--------------------+--------------------+--------------------+-------+--------------------+-------------------+--------+-----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('datosTarea.csv', header=True, inferSchema=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtro de datos\n",
    ">Consigue todas las empresas que empiecen con 'M' y tengan entre 4000 y 7000 empleados. Sólo muestra los nombres y el número de empleados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+\n",
      "|                Name|Number of employees|\n",
      "+--------------------+-------------------+\n",
      "|Mckinney, Riley a...|               4952|\n",
      "|       Mcintosh-Mora|               4389|\n",
      "|     Mckenzie-Melton|               4589|\n",
      "|          Massey LLC|               5004|\n",
      "|        Mays-Preston|               5786|\n",
      "+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "# Filtrar por nombre y número de empleados\n",
    "filtered_df1 = df.filter(\n",
    "    (col(\"Name\").startswith(\"M\")) & \n",
    "    (col(\"Number of employees\") >= 4000) & \n",
    "    (col(\"Number of employees\") <= 7000)\n",
    ").select(\"Name\", \"Number of employees\")\n",
    "\n",
    "filtered_df1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Consigue todos los países que no inicien con las letras 'b', 's' y 'm', pero que tampoco tengan un netword mayor a 500000. Muestra el nombre de la compañía, el país y el networth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------+\n",
      "|                Name|             Country|Networth|\n",
      "+--------------------+--------------------+--------+\n",
      "|         Ferrell LLC|    Papua New Guinea|  402269|\n",
      "|      Holder-Sellers|        Turkmenistan|  105914|\n",
      "|Keller, Campos an...|             Liberia|  329130|\n",
      "|      Pacheco-Spears|              Sweden|   88435|\n",
      "|         Harrell LLC|          Guadeloupe|  251274|\n",
      "|         Jenkins Inc|        South Africa|  139725|\n",
      "|Dickson, Richmond...|      Czech Republic|  359030|\n",
      "|        Prince-David|    Christmas Island|  120289|\n",
      "|         Rivas Group|           Australia|  477824|\n",
      "|Sloan, Mays and W...|                Chad|   41975|\n",
      "|Glass, Barrera an...|     Kyrgyz Republic|  300150|\n",
      "|          Pineda-Cox|             Bolivia|  150880|\n",
      "|Baker, Mccann and...|               Kenya|  188370|\n",
      "|            Hahn PLC|             Belarus|  427224|\n",
      "|Valentine, Fergus...|              Jersey|  412274|\n",
      "|           Walls LLC|          Cape Verde|  192969|\n",
      "|Mitchell, Warren ...| Trinidad and Tobago|  438839|\n",
      "|      Walton-Barnett|      Western Sahara|  200789|\n",
      "|     Bartlett-Arroyo|Northern Mariana ...|  458504|\n",
      "|         Berg-Sparks|              Canada|  238394|\n",
      "+--------------------+--------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_df2 = df.filter(\n",
    "    (~col(\"Country\").startswith(\"b\")) & \n",
    "    (~col(\"Country\").startswith(\"s\")) & \n",
    "    (~col(\"Country\").startswith(\"m\")) & \n",
    "    (col(\"Networth\") <= 500000)\n",
    ").select(\"Name\", \"Country\", \"Networth\")\n",
    "\n",
    "filtered_df2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones\n",
    "Crea una función con @pandas_udf que que le reste a los profits la media en cada renglón. Crea una nueva columna que muestre los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+--------------------+--------------------+--------------------+--------------------+-------+--------------------+-------------------+--------+-----------+------+-------------------+\n",
      "|Index|Organization Id|                Name|             Website|             Country|         Description|Founded|            Industry|Number of employees|Networth|stock_price|profit|  profit_minus_mean|\n",
      "+-----+---------------+--------------------+--------------------+--------------------+--------------------+-------+--------------------+-------------------+--------+-----------+------+-------------------+\n",
      "|    1|FAB0d41d5b5d22c|         Ferrell LLC|  https://price.net/|    Papua New Guinea|Horizontal empowe...|   1990|            Plastics|               3498|  402269|         33| 12125|-248.64999999999964|\n",
      "|    2|6A7EdDEA9FaDC52|Mckinney, Riley a...|http://www.hall-b...|             Finland|User-centric syst...|   2015|Glass / Ceramics ...|               4952|  569480|         49| 12001|-372.64999999999964|\n",
      "|    3|0bFED1ADAE4bcC1|          Hester Ltd|http://sullivan-r...|               China|Switchable scalab...|   1971|       Public Safety|               5287|  608005|         26| 17121|            4747.35|\n",
      "|    4|2bFC1Be8a4ce42f|      Holder-Sellers| https://becker.com/|        Turkmenistan|De-engineered sys...|   2004|          Automotive|                921|  105914|         23|  8200|           -4173.65|\n",
      "|    5|9eE8A6a4Eb96C24|         Mayer Group|http://www.brewer...|           Mauritius|Synchronized need...|   1991|      Transportation|               7870|  905049|         31|  8599|-3774.6499999999996|\n",
      "|    6|cC757116fe1C085|      Henry-Thompson|   http://morse.net/|             Bahamas|Face-to-face well...|   1992|Primary / Seconda...|               4914|  565110|         49|  5389|           -6984.65|\n",
      "|    7|219233e8aFF1BC3|      Hansen-Everett|https://www.kidd....|            Pakistan|Seamless disinter...|   2018| Publishing Industry|               7832|  900679|         13|  5700|           -6673.65|\n",
      "|    8|ccc93DCF81a31CD|       Mcintosh-Mora|https://www.brook...|Heard Island and ...|Centralized attit...|   1970|     Import / Export|               4389|  504734|         19|  5830|           -6543.65|\n",
      "|    9|0B4F93aA06ED03e|            Carr Inc|    http://ross.com/|              Kuwait|Distributed impac...|   1996|            Plastics|               8167|  939204|         16| 15786| 3412.3500000000004|\n",
      "|   10|738b5aDe6B1C6A5|          Gaines Inc|http://sandoval-h...|          Uzbekistan|Multi-lateral sca...|   1997|Outsourcing / Off...|               9698| 1115270|         16| 14835| 2461.3500000000004|\n",
      "|   11|AE61b8Ffebbc476|          Kidd Group|http://www.lyons....|Bouvet Island (Bo...|Proactive foregro...|   2001|Primary / Seconda...|               7473|  859394|         45| 15424| 3050.3500000000004|\n",
      "|   12|eb3B7D06cCdD609|        Crane-Clarke|https://www.sando...|             Denmark|Front-line clear-...|   2014|    Food / Beverages|               9011| 1036264|         26|  8297|-4076.6499999999996|\n",
      "|   13|8D0c29189C9798B|Keller, Campos an...|https://www.garne...|             Liberia|Ameliorated direc...|   2020|Museums / Institu...|               2862|  329130|         28| 17043|            4669.35|\n",
      "|   14|D2c91cc03CA394c|         Glover-Pope|http://www.silva....|United Arab Emirates|Persevering conte...|   2013|    Medical Practice|               9079| 1044084|         28| 17809|            5435.35|\n",
      "|   15|C8AC1eaf9C036F4|      Pacheco-Spears|https://aguilar.com/|              Sweden|Secured logistica...|   1984|            Maritime|                769|   88435|         34| 12677| 303.35000000000036|\n",
      "|   16|b5D10A14f7a8AfE|         Hodge-Ayers|http://www.archer...|            Honduras|Future-proofed ra...|   1990| Facilities Services|               8508|  978419|         13| 15797| 3423.3500000000004|\n",
      "|   17|68139b5C4De03B4|Bowers, Guerra an...|http://www.carril...|              Uganda|De-engineered tra...|   1972|Primary / Seconda...|               6986|  803389|         34| 12530| 156.35000000000036|\n",
      "|   18|5c2EffEfdba2BdF|     Mckenzie-Melton|http://montoya-th...|           Hong Kong|Reverse-engineere...|   1998|Investment Manage...|               4589|  527735|         11| 16958|            4584.35|\n",
      "|   19|ba179F19F7925f5|         Branch-Mann|http://www.lozano...|            Botswana|Adaptive intangib...|   1999|Architecture / Pl...|               7961|  915514|         47|  8745|-3628.6499999999996|\n",
      "|   20|c1Ce9B350BAc66b|      Weiss and Sons|https://barrett.com/|               Korea|Sharable optimal ...|   2011|            Plastics|               5984|  688160|         46| 18079|            5705.35|\n",
      "+-----+---------------+--------------------+--------------------+--------------------+--------------------+-------+--------------------+-------------------+--------+-----------+------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# Calcular la media de la columna 'profits'\n",
    "mean_profit = df.select(col(\"profit\")).groupBy().avg().first()[0]\n",
    "\n",
    "# Crear una UDF para restar la media de la columna 'profit'\n",
    "@udf(DoubleType())\n",
    "def subtract_mean(value):\n",
    "    return value - mean_profit\n",
    "\n",
    "# Aplicar la UDF al DataFrame para crear una nueva columna\n",
    "df_with_subtracted_mean = df.withColumn(\"profit_minus_mean\", subtract_mean(col(\"profit\")))\n",
    "\n",
    "# Muestra los resultados\n",
    "df_with_subtracted_mean.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping data\n",
    ">Agrupa por industry y muestra cuáles son las empresas con el profit más alto. Muestra los primeros tres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|            Industry|MaxProfit|\n",
      "+--------------------+---------+\n",
      "|  Legislative Office|    19363|\n",
      "|Museums / Institu...|    19079|\n",
      "|             Farming|    18850|\n",
      "+--------------------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import max, avg\n",
    "\n",
    "# Agrupar por 'industry' y encontrar la empresa con el profit más alto en cada industria\n",
    "top_profits_by_industry = df.groupBy(\"Industry\").agg(max(\"profit\").alias(\"MaxProfit\"))\n",
    "\n",
    "# Ordenar por 'MaxProfit' en orden descendente y mostrar las tres primeras\n",
    "top_profits_by_industry.orderBy(col(\"MaxProfit\").desc()).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Agrupa por industry y calcula el promedio de empleados que tienen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|            Industry| AverageEmployees|\n",
      "+--------------------+-----------------+\n",
      "|Primary / Seconda...|6457.666666666667|\n",
      "|     Broadcast Media|           2589.0|\n",
      "|           Wholesale|           5010.0|\n",
      "|Investment Manage...|           3133.5|\n",
      "|    Food / Beverages|           9011.0|\n",
      "|  Gambling / Casinos|           4873.0|\n",
      "|Logistics / Procu...|           4155.0|\n",
      "|            Maritime|            769.0|\n",
      "|            Wireless|           6146.0|\n",
      "|Education Management|            339.0|\n",
      "|       Arts / Crafts|           2800.0|\n",
      "|           Insurance|           1215.0|\n",
      "|  Financial Services|           5157.0|\n",
      "|Business Supplies...|           9097.0|\n",
      "|Consumer Electronics|           5022.0|\n",
      "|       Public Safety|           5287.0|\n",
      "|Information Techn...|           3934.0|\n",
      "|Civic / Social Or...|           2442.0|\n",
      "|      Consumer Goods|           9069.0|\n",
      "|Glass / Ceramics ...|           4952.0|\n",
      "+--------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Agrupar por 'industry' y calcular el promedio de empleados\n",
    "average_employees_by_industry = df.groupBy(\"Industry\").agg(avg(\"Number of employees\").alias(\"AverageEmployees\"))\n",
    "\n",
    "# Mostrar los resultados\n",
    "average_employees_by_industry.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL\n",
    ">Usando Spark SQL, obtén cuántas empresas se fundaron despúes del 2000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|total_empresas_post_2000|\n",
      "+------------------------+\n",
      "|                      38|\n",
      "+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Registrar el DataFrame como una vista temporal SQL\n",
    "df.createOrReplaceTempView(\"empresas\")\n",
    "\n",
    "# Ejecutar la consulta SQL para obtener el número de empresas fundadas después del 2000\n",
    "query = \"\"\"\n",
    "SELECT COUNT(*) as total_empresas_post_2000\n",
    "FROM empresas\n",
    "WHERE Founded > 2000\n",
    "\"\"\"\n",
    "\n",
    "# Ejecutar la consulta y mostrar los resultados\n",
    "result = spark.sql(query)\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Regresión Lineal\n",
    ">Con número de empleados, networth y stock price, obtén una predicción del profit a través de una regresión lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/12/07 00:19:10 WARN Instrumentation: [948727ad] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4506.28\n",
      "R2: 0.0348812\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "\n",
    "# Asignar los nombres de las columnas a variables para fácil referencia\n",
    "features = ['Number of employees', 'Networth', 'stock_price']\n",
    "label = 'profit'\n",
    "\n",
    "# Preparar los datos para el modelo de regresión lineal\n",
    "assembler = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
    "data = assembler.transform(df)\n",
    "\n",
    "# Definir la columna de características y la columna objetivo\n",
    "data = data.withColumnRenamed(label, \"label\").select(\"features\", \"label\")\n",
    "\n",
    "# Dividir los datos en conjunto de entrenamiento y conjunto de prueba\n",
    "train_data, test_data = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Inicializar el modelo de regresión lineal\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "lr_model = lr.fit(train_data)\n",
    "\n",
    "# Predecir los profits en el conjunto de prueba\n",
    "predictions = lr_model.transform(test_data)\n",
    "\n",
    "# Selección de columnas para convertir a DataFrame de Pandas\n",
    "selected_columns = predictions.select(\"features\", \"label\", \"prediction\")\n",
    "\n",
    "# Evaluar las predicciones\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "# Calcular el error cuadrático medio (Root Mean Squared Error, RMSE)\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"RMSE: %g\" % rmse)\n",
    "\n",
    "# También puedes evaluar otras métricas, como el coeficiente de determinación (R2)\n",
    "r2 = evaluator.evaluate(predictions, {evaluator.metricName: \"r2\"})\n",
    "print(\"R2: %g\" % r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Una vez que obtengas los resultados, a través del api de pandas, conviértelo en un pandas on spark DataFrame y pásalo a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convierte el DataFrame de Spark a un DataFrame de Pandas usando Pandas API\n",
    "@pandas_udf(selected_columns.schema, PandasUDFType.GROUPED_MAP)\n",
    "def to_pandas_udf(pdf):\n",
    "    return pdf\n",
    "\n",
    "# Selección de columnas para convertir a DataFrame de Pandas\n",
    "pandas_df = predictions.select(\"features\", \"label\", \"prediction\").toPandas()\n",
    "\n",
    "# Guardar el DataFrame de Pandas como CSV\n",
    "pandas_df.to_csv(\"predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
